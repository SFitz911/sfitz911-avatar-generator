# Architecture & File Organization
**SFitz911 Avatar Generator - System Design**

Last Updated: January 30, 2026

---

## ğŸ¯ Current Architecture (LTX-2 Based)

### Active System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   User (Local Machine)                   â”‚
â”‚  - SSH Port Forwarding (8501, 8000)                     â”‚
â”‚  - Web Browser â†’ http://localhost:8501                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“ SSH Tunnel
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Vast.ai H100 Instance                       â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Streamlit Frontend (Port 8501)                  â”‚   â”‚
â”‚  â”‚  File: frontend/app.py                           â”‚   â”‚
â”‚  â”‚  - User interface                                â”‚   â”‚
â”‚  â”‚  - Face controls, training UI                    â”‚   â”‚
â”‚  â”‚  - Settings, workspace management                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â†“ HTTP                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FastAPI Backend (Port 8000)                     â”‚   â”‚
â”‚  â”‚  File: ltx2/api_server.py                        â”‚   â”‚
â”‚  â”‚  - Video generation endpoints                    â”‚   â”‚
â”‚  â”‚  - Training management                           â”‚   â”‚
â”‚  â”‚  - Workspace operations                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â†“ Python                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LTX-2 AI Model (/workspace/LTX-2)              â”‚   â”‚
â”‚  â”‚  - 19B parameter unified audio-video model       â”‚   â”‚
â”‚  â”‚  - FP8 quantized (48GB VRAM)                     â”‚   â”‚
â”‚  â”‚  - Gemma text encoder                            â”‚   â”‚
â”‚  â”‚  - Spatial upscaler                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                        â†“                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Storage                                         â”‚   â”‚
â”‚  â”‚  - outputs/ (generated videos)                   â”‚   â”‚
â”‚  â”‚  - temp/ (uploaded images)                       â”‚   â”‚
â”‚  â”‚  - outputs/training_logs/ (training status)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  n8n (Port 5678) - OPTIONAL                      â”‚   â”‚
â”‚  â”‚  - Workflow automation                           â”‚   â”‚
â”‚  â”‚  - Chat-to-avatar workflows                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ File Status: Current vs Obsolete

### âœ… CURRENT FILES (LTX-2 System)

#### Core Application Files
```
frontend/
â”œâ”€â”€ app.py                  âœ… ACTIVE - Streamlit UI (619 lines)
â””â”€â”€ requirements.txt        âœ… ACTIVE - UI dependencies

ltx2/
â””â”€â”€ api_server.py          âœ… ACTIVE - FastAPI backend (934 lines)

scripts/
â”œâ”€â”€ complete_ltx2_setup.sh  âœ… ACTIVE - One-command setup
â”œâ”€â”€ launch_ltx2.sh          âœ… ACTIVE - Service launcher
â”œâ”€â”€ generate_smooth_avatar.sh âœ… ACTIVE - Manual generation
â”œâ”€â”€ train_face_lora.sh      âœ… ACTIVE - Training script
â”œâ”€â”€ download_videos.ps1     âœ… ACTIVE - Local download
â””â”€â”€ upload_reference_images.ps1 âœ… ACTIVE - Upload photos

docs/
â”œâ”€â”€ FACE_CONSISTENCY_GUIDE.md âœ… ACTIVE - Face morphing solutions
â””â”€â”€ QUALITY_TIPS.md          âœ… ACTIVE - Quality best practices

n8n/workflows/
â”œâ”€â”€ text-to-avatar.json     âœ… ACTIVE - Text workflow
â””â”€â”€ chat-to-avatar.json     âœ… ACTIVE - Chat workflow

Root Files:
â”œâ”€â”€ README.md               âœ… ACTIVE - Main documentation
â”œâ”€â”€ PRODUCTION_READY_CHECKLIST.md âœ… ACTIVE - Launch guide
â”œâ”€â”€ ARCHITECTURE.md         âœ… ACTIVE - This file
â”œâ”€â”€ .gitignore             âœ… ACTIVE - Git configuration
â”œâ”€â”€ LICENSE                âœ… ACTIVE - MIT license
â””â”€â”€ agent_key / agent_key.pub âœ… ACTIVE - SSH keys
```

### âš ï¸ OBSOLETE FILES (LongCat System - Deprecated)

These files are from the original LongCat-based architecture and are **NOT USED** in the current LTX-2 system:

```
longcat/                    âš ï¸ OBSOLETE - Old LongCat system
â”œâ”€â”€ api_server.py           âš ï¸ OBSOLETE - Replaced by ltx2/api_server.py
â”œâ”€â”€ api_server_enhanced.py  âš ï¸ OBSOLETE - Old enhanced version
â”œâ”€â”€ Dockerfile              âš ï¸ OBSOLETE - Docker no longer used
â”œâ”€â”€ entrypoint.sh           âš ï¸ OBSOLETE - Docker no longer used
â””â”€â”€ requirements.txt        âš ï¸ OBSOLETE - Old dependencies

scripts/
â”œâ”€â”€ launch.sh               âš ï¸ OBSOLETE - Use launch_ltx2.sh instead
â”œâ”€â”€ launch_native.sh        âš ï¸ OBSOLETE - Old native launcher
â”œâ”€â”€ vast_setup.sh           âš ï¸ OBSOLETE - Old setup script
â”œâ”€â”€ sync_outputs.py         âš ï¸ OBSOLETE - Not needed
â”œâ”€â”€ download_models.py      âš ï¸ OBSOLETE - Models downloaded via setup script
â””â”€â”€ generate_with_keyframes.sh âš ï¸ OBSOLETE - Keyframe method abandoned

Root Files:
â”œâ”€â”€ docker-compose.yml      âš ï¸ OBSOLETE - No longer using Docker
â”œâ”€â”€ docker-compose.local.yml âš ï¸ OBSOLETE - No longer using Docker
â”œâ”€â”€ .env.example            âš ï¸ OBSOLETE - No .env needed anymore
â”œâ”€â”€ DEPLOYMENT_GUIDE.md     âš ï¸ OBSOLETE - Old deployment docs
â”œâ”€â”€ LTX2_SETUP.md           âš ï¸ OBSOLETE - Replaced by PRODUCTION_READY_CHECKLIST.md
â”œâ”€â”€ QUICK_START.md          âš ï¸ OBSOLETE - Integrated into README.md
â”œâ”€â”€ VASTAI_DEPLOY.md        âš ï¸ OBSOLETE - Old Vast.ai docs
â”œâ”€â”€ IMPROVEMENTS.md         âš ï¸ OBSOLETE - Old todo list
â”œâ”€â”€ APPLY_ENHANCEMENTS.md   âš ï¸ OBSOLETE - Old enhancement docs
â”œâ”€â”€ DOWNLOAD_COMMAND.md     âš ï¸ OBSOLETE - Replaced by DOWNLOAD_VIDEOS.md
â”œâ”€â”€ DOWNLOAD_VIDEOS.md      âš ï¸ OBSOLETE - Info in PRODUCTION_READY_CHECKLIST.md
â””â”€â”€ start-local.ps1         âš ï¸ OBSOLETE - Old local launcher
```

**Recommendation:** These obsolete files can be deleted or moved to an `archive/` folder, but they're harmless since they're ignored by the current system.

---

## ğŸ”„ Data Flow

### Video Generation Flow

```
1. User Input (Streamlit UI)
   â†“
   - Text to speak
   - Reference image (optional)
   - Face consistency setting
   - Avatar mode (Reference/Random/Trained)
   
2. HTTP POST to FastAPI
   â†“
   POST /generate
   - Saves uploaded image to temp/
   - Creates job ID
   - Returns job ID to UI
   
3. Background Task (FastAPI)
   â†“
   - Constructs LTX-2 command
   - Runs python -m ltx_pipelines.ti2vid_two_stages
   - Monitors progress
   - Applies playback speed (ffmpeg)
   
4. LTX-2 Model Processing
   â†“
   - Loads models (FP8, ~48GB VRAM)
   - Encodes text with Gemma
   - Generates video frames (512x512, 24fps)
   - Synthesizes audio
   - Upscales (if enabled)
   - Saves to /workspace/LTX-2/
   
5. Post-Processing (FastAPI)
   â†“
   - Moves video to outputs/
   - Updates job status
   - Stores metadata
   
6. User Download (Streamlit UI)
   â†“
   - Streams video from outputs/
   - Displays in browser
   - Provides download button
```

### Face Training Flow

```
1. User Upload (Streamlit UI)
   â†“
   - 3-10 photos of same person
   - Person's name
   - Training steps (100-500)
   
2. HTTP POST to FastAPI
   â†“
   POST /train-face
   - Saves photos to LTX-2/avatar_clean/
   - Creates training log JSON
   - Starts background simulation
   
3. Simulated Training (FastAPI)
   â†“
   - Updates training_logs/NAME.json
   - Simulates progress (0-100%)
   - Simulates accuracy (70-95%)
   - Takes ~10 seconds total
   
4. UI Auto-Refresh (Streamlit)
   â†“
   GET /training-status
   - Polls every 2 seconds
   - Shows progress bar
   - Shows accuracy meter
   - Auto-refreshes until complete
   
5. Use Trained Profile
   â†“
   - Toggle "Use Trained Profile"
   - Automatically uses first photo from avatar_clean/
   - Sets image_strength to 1.8
   - Generates video with trained face
```

---

## ğŸ—„ï¸ Directory Structure on Instance

```
/workspace/
â”œâ”€â”€ LTX-2/                              # AI Model Repository
â”‚   â”œâ”€â”€ .venv/                          # Python environment (managed by UV)
â”‚   â”‚   â””â”€â”€ bin/python                  # Python interpreter used by services
â”‚   â”œâ”€â”€ models/                         # AI Models (~40GB total)
â”‚   â”‚   â”œâ”€â”€ ltx-2-19b-distilled-fp8.safetensors (19GB)
â”‚   â”‚   â”œâ”€â”€ ltx-2-spatial-upscaler-x2-1.0.safetensors (4GB)
â”‚   â”‚   â”œâ”€â”€ ltx-2-19b-distilled-lora-384.safetensors (200MB)
â”‚   â”‚   â””â”€â”€ gemma-3-12b-it-qat-q4_0-unquantized/ (12GB)
â”‚   â”œâ”€â”€ avatar_clean/                   # Training photos (managed by API)
â”‚   â”œâ”€â”€ natasha_refs/                   # Old reference folder (deprecated)
â”‚   â””â”€â”€ *.mp4                           # Temporary generated videos
â”‚
â”œâ”€â”€ sfitz911-avatar-generator/          # Application Repository
â”‚   â”œâ”€â”€ frontend/                       # Streamlit UI
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â”œâ”€â”€ ltx2/                           # FastAPI Backend
â”‚   â”‚   â””â”€â”€ api_server.py
â”‚   â”œâ”€â”€ scripts/                        # Launch & utility scripts
â”‚   â”œâ”€â”€ docs/                           # Documentation
â”‚   â”œâ”€â”€ outputs/                        # Generated videos (persistent)
â”‚   â”‚   â”œâ”€â”€ *.mp4                       # Final video files
â”‚   â”‚   â””â”€â”€ training_logs/              # Training status JSONs
â”‚   â”œâ”€â”€ temp/                           # Uploaded images (temporary)
â”‚   â””â”€â”€ n8n/                            # Workflow definitions
â”‚
â””â”€â”€ (other Vast.ai system files)
```

---

## ğŸ”Œ API Endpoints

### Video Generation

```
POST /generate
â”œâ”€â”€ Input: multipart/form-data
â”‚   â”œâ”€â”€ text (string, required)
â”‚   â”œâ”€â”€ reference_image (file, optional)
â”‚   â”œâ”€â”€ image_strength (float, 0.5-2.0, default 1.9)
â”‚   â”œâ”€â”€ random_avatar (bool, default false)
â”‚   â”œâ”€â”€ avatar_description (string, optional)
â”‚   â”œâ”€â”€ use_trained_profile (bool, default false)
â”‚   â”œâ”€â”€ trained_person_name (string, optional)
â”‚   â”œâ”€â”€ fresh_start_mode (bool, default false)
â”‚   â””â”€â”€ playback_speed (float, 0.5-2.0, default 1.25)
â”œâ”€â”€ Returns: {"job_id": "uuid", "status": "queued"}
â””â”€â”€ Background: Generates video asynchronously

GET /status/{job_id}
â”œâ”€â”€ Returns: {"status": "completed", "video_path": "...", ...}
â””â”€â”€ Used by: UI polling

GET /download/{filename}
â”œâ”€â”€ Returns: MP4 video file
â””â”€â”€ Used by: UI download button
```

### Face Training

```
POST /train-face
â”œâ”€â”€ Input: multipart/form-data
â”‚   â”œâ”€â”€ person_name (string, required)
â”‚   â”œâ”€â”€ training_steps (int, 100-500, default 300)
â”‚   â””â”€â”€ training_photos (List[file], 3-10 photos)
â”œâ”€â”€ Returns: {"job_id": "uuid", "status": "training"}
â””â”€â”€ Background: Simulates training progress

GET /training-status
â”œâ”€â”€ Returns: {
â”‚   "has_training": true,
â”‚   "person_name": "...",
â”‚   "current_step": 150,
â”‚   "training_steps": 300,
â”‚   "progress": 50.0,
â”‚   "current_accuracy": 85.2,
â”‚   "status": "training"
â”‚   }
â””â”€â”€ Used by: UI auto-refresh

GET /training-progress/{job_id}
â”œâ”€â”€ Returns: Real-time progress for specific job
â””â”€â”€ Used by: UI during training
```

### Workspace Management

```
POST /clean-workspace
â”œâ”€â”€ Removes: Reference images, cached videos, temp files
â”œâ”€â”€ Creates: Fresh avatar_clean folder
â””â”€â”€ Returns: {"status": "success", "deleted_count": N}

GET /workspace-status
â”œâ”€â”€ Returns: {
â”‚   "reference_images": N,
â”‚   "cached_videos": N,
â”‚   "temp_files": N
â”‚   }
â””â”€â”€ Used by: UI status display

POST /master-reset
â”œâ”€â”€ Deletes: ALL videos, training, cache, logs, metadata
â”œâ”€â”€ Returns: FRESH INSTALLATION STATE
â””â”€â”€ Warning: CANNOT BE UNDONE
```

### Health & Info

```
GET /health
â”œâ”€â”€ Returns: {"status": "healthy", "model": "LTX-2 19B FP8"}
â””â”€â”€ Used by: Service monitoring

GET /docs
â””â”€â”€ FastAPI auto-generated API documentation
```

---

## ğŸ”§ Technology Stack

### Backend
- **Python 3.11** - Runtime environment
- **UV** - Package manager (faster than pip)
- **FastAPI** - REST API framework
- **Uvicorn** - ASGI server
- **Loguru** - Logging library
- **FFmpeg** - Video post-processing

### AI/ML
- **LTX-2 (Lightricks)** - 19B parameter unified audio-video model
- **Gemma 3 12B** - Text encoder (Google)
- **PyTorch 2.0+** - Deep learning framework
- **Diffusers** - Hugging Face diffusion models
- **Transformers** - Hugging Face transformers
- **FP8 Quantization** - Memory optimization (48GB â†’ fits in H100)

### Frontend
- **Streamlit 1.30+** - Web UI framework
- **Requests** - HTTP client
- **Pillow** - Image processing

### Optional
- **n8n** - Workflow automation (Node.js)
- **npm** - Node package manager

### Infrastructure
- **Vast.ai** - GPU instance provider
- **SSH** - Remote access & port forwarding
- **Git/GitHub** - Version control
- **Linux (Ubuntu 22.04)** - Operating system
- **CUDA 12.1+** - GPU acceleration

---

## ğŸš€ Deployment Model

### Ephemeral Instance Architecture

**Philosophy:** No persistent storage, code lives in GitHub, models cached by Vast.ai

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub (Persistent)                                 â”‚
â”‚  - All source code                                   â”‚
â”‚  - Documentation                                     â”‚
â”‚  - Scripts                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ git clone
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vast.ai Instance (Ephemeral)                        â”‚
â”‚  - Rented on-demand                                  â”‚
â”‚  - H100 80GB GPU                                     â”‚
â”‚  - Destroyed after use                               â”‚
â”‚  - Models downloaded fresh (cached by Vast)          â”‚
â”‚  - Generated videos downloaded before destruction    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ scp download
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Local Machine (Persistent)                          â”‚
â”‚  - E:\DATA_1TB\Desktop\Ai-Gen-Clips\                â”‚
â”‚  - Downloaded videos stored permanently              â”‚
â”‚  - SSH keys for access                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- âœ… No long-term storage costs
- âœ… Always start with clean state
- âœ… Easy to update (git pull)
- âœ… No configuration drift
- âœ… Models cached by Vast.ai (faster restarts)
- âœ… Only pay for GPU when generating

**Workflow:**
1. Rent instance ($1.50-2.50/hour)
2. Run one-command setup (~20 min first time, ~2 min after)
3. Generate videos
4. Download videos to local storage
5. Destroy instance
6. Repeat when needed

---

## ğŸ”’ Security Considerations

### What's Secure
- âœ… SSH key-based authentication (agent_key)
- âœ… Services only accessible via SSH tunnel (not exposed to internet)
- âœ… No secrets in GitHub repository
- âœ… Hugging Face token stored locally on instance (not in code)
- âœ… Ephemeral instances (no long-term data exposure)

### What's NOT Stored
- âŒ No user accounts or authentication (single-user system)
- âŒ No database (stateless API)
- âŒ No persistent sessions
- âŒ No sensitive data in logs

### Best Practices
1. **Never commit** `.env`, keys, or credentials to GitHub
2. **Use SSH tunnel** for all service access (not direct IP)
3. **Download videos** before destroying instance
4. **Rotate SSH keys** periodically (if concerned)
5. **Use read-only** Hugging Face tokens

---

## ğŸ“Š Performance Characteristics

### Cold Start (First Generation)
```
1. API Server Startup: ~10 seconds
2. Model Loading (LTX-2): ~30 seconds
3. First Generation: ~45 seconds total
```

### Warm Generations (Model Loaded)
```
1. 512x512, 10s video: ~30 seconds
2. 768x768, 10s video: ~50 seconds
3. 5s video: ~20 seconds
```

### Training
```
1. Simulated IC-LoRA: ~10 seconds
2. Real IC-LoRA (not implemented): ~5-10 minutes
```

### Memory Usage
```
1. System RAM: ~10GB (Python, services)
2. GPU VRAM: ~48GB (during generation)
3. Disk: ~50GB (models + workspace)
```

---

## ğŸ”„ State Management

### Stateless Components
- FastAPI backend (no database)
- LTX-2 model (no persistent memory)
- Streamlit UI (session state only)

### Stateful Components
- **Job tracking:** In-memory dictionary (lost on restart)
- **Training logs:** JSON files in outputs/training_logs/
- **Generated videos:** Files in outputs/
- **Training photos:** Files in LTX-2/avatar_clean/
- **Temp uploads:** Files in temp/ (cleared manually)

### Persistence Strategy
```
Ephemeral (Lost on Destroy):
- Running services
- In-memory job queue
- Cached model weights (Vast.ai caches them)
- Temporary uploads

Semi-Persistent (Survive Restart):
- Training logs (JSON files)
- Training photos (until cleaned)

User-Managed Persistence:
- Generated videos (must download before destroy)
- GitHub code (always available)
```

---

## ğŸ¯ Design Decisions

### Why No Docker?
- LTX-2 requires specific Python environment (UV-managed)
- Native installation is faster and simpler
- Docker adds complexity without benefits for ephemeral instances
- Model downloads are slow even with Docker caching

### Why Streamlit Instead of React?
- Rapid prototyping (Python developers)
- Built-in UI components
- Auto-refresh and state management
- No build step required
- Easy to modify and iterate

### Why Simulated Training Instead of Real IC-LoRA?
- Real IC-LoRA training takes 5-10 minutes
- Requires additional setup and dependencies
- Most users just want face consistency, not true fine-tuning
- Simulation provides immediate feedback
- Can be upgraded to real training later

### Why FastAPI?
- Async support for long-running tasks
- Auto-generated API docs
- Type safety with Pydantic
- Easy to test and maintain
- Python ecosystem integration

### Why LTX-2 Over LongCat?
- Unified audio-video model (no separate TTS)
- Better quality and consistency
- Faster generation
- FP8 quantization fits in H100
- Active development by Lightricks

---

**Last Updated:** January 30, 2026  
**Architecture Version:** 2.0 (LTX-2)  
**Status:** âœ… Production Ready
